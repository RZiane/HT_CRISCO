{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m traverse_dir\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mextract_sent_from_xml\u001b[39;00m \u001b[39mimport\u001b[39;00m extract_stats\n\u001b[1;32m      4\u001b[0m input_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/ziane212/projects/micle-Mathieu-HIGH-TECH-XML-TEI/HIGH-TECH/XML-TEI/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m traverse_dir(input_path):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tools'"
     ]
    }
   ],
   "source": [
    "from utils import traverse_dir\n",
    "from tools.extract_sent_from_xml import extract_stats\n",
    "\n",
    "input_path = '/home/ziane212/projects/micle-Mathieu-HIGH-TECH-XML-TEI/HIGH-TECH/XML-TEI/'\n",
    "\n",
    "for file in traverse_dir(input_path):\n",
    "    print(file)\n",
    "    extract_stats(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PRESTO': [['\\ufeffClasse', 'Presto_POS', 'PRESTO', 'UPENN', 'UPOS', 'AND\\n']], 'As': [['adjectif possessif', 'ADJ', 'As', 'ADJZ', 'ADJ', 'a\\n']], 'Ag': [['adjectif qualificatif', 'ADJ', 'Ag', 'ADJ', 'ADJ', 'a\\n'], ['adjectif superlatif', 'ADJ', 'Ag', 'ADJS', 'ADJ', 'a\\n']], 'Rg': [['adverbe comparatif', 'ADV', 'Rg', 'ADVR', 'ADV', 'adv\\n'], ['adverbe superlatif', 'ADV', 'Rg', 'ADVS', 'ADV', 'adv\\n'], ['adverbe (autre)', 'ADV', 'Rg', 'ADV', 'ADV', 'adv\\n'], ['adverbe (autre)', 'ADV', 'Rg', 'WH', 'ADV', 'adv\\n'], ['adverbe (autre)', 'ADV', 'Rg', 'Q', 'ADV', 'adv\\n'], ['adverbe (autre)', 'ADV', 'Rg', 'QR', 'ADV', 'adv\\n']], 'Rt': [['adverbe interrogatif/relatif et exclamatif', 'ADV', 'Rt', 'WADV', 'ADV', 'adv\\n']], 'Rp': [['adverbe négatif', 'ADV', 'Rp', 'ADVNEG', 'ADV', 'adv\\n'], ['adverbe négation NE', 'ADV', 'Rp', 'NEG', 'ADV', 'adv\\n']], 'Vun': [[\"auxiliaire AVOIR à l'infinitif\", 'VER', 'Vun', 'AX', 'AUX', 'v\\n'], [\"verbe AVOIR à l'infinitif\", 'VER', 'Vun', 'AX', 'VERB', 'v\\n'], [\"auxiliaire ÊTRE à l'infinitif\", 'VER', 'Vun', 'EX', 'AUX', 'v\\n'], [\"verbe ÊTRE à l'infinitif\", 'VER', 'Vun', 'EX', 'VERB', 'v\\n']], 'Ga': [['auxiliaire AVOIR au gérondif', 'PAG', 'Ga', 'AG', 'AUX', 'v\\n'], ['verbe AVOIR au gérondif', 'PAG', 'Ga', 'AG', 'VERB', 'v\\n'], ['auxiliaire ÊTRE au gérondif', 'PAG', 'Ga', 'EG', 'AUX', 'v\\n'], ['verbe ÊTRE au gérondif', 'PAG', 'Ga', 'EG', 'VERB', 'v\\n'], ['verbe semi-auxiliaire* au gérondif (emploi non-modal**)', 'PAG', 'Ga', 'MDG', 'VERB', 'v\\n'], ['verbe semi-auxiliaire* au gérondif (emploi modal***)', 'PAG', 'Ga', 'MDG', 'AUX', 'v\\n'], ['verbe principal au gérondif', 'PAG', 'Ga', 'VG', 'VERB', 'v\\n']], 'Ge': [['auxiliaire AVOIR au participe passé', 'PAG', 'Ge', 'APP', 'AUX', 'v\\n'], ['verbe AVOIR au participe passé', 'PAG', 'Ge', 'APP', 'VERB', 'v\\n'], ['auxiliaire ÊTRE au participe passé', 'PAG', 'Ge', 'EPP', 'AUX', 'v\\n'], ['verbe ÊTRE au participe passé', 'PAG', 'Ge', 'EPP', 'VERB', 'v\\n'], ['verbe semi-auxiliaire* au participe passé (emploi non-modal**)', 'PAG', 'Ge', 'MDPP', 'VERB', 'v\\n'], ['verbe semi-auxiliaire* au participe passé (emploi modal***)', 'PAG', 'Ge', 'MDPP', 'AUX', 'v\\n'], ['verbe principal au participe passé', 'PAG', 'Ge', 'VPP', 'VERB', 'v\\n']], 'Vuc': [['auxiliaire AVOIR conjugué', 'VER', 'Vuc', 'AJ', 'AUX', 'v\\n'], ['verbe AVOIR conjugué', 'VER', 'Vuc', 'AJ', 'VERB', 'v\\n'], ['auxiliaire ÊTRE conjugué', 'VER', 'Vuc', 'EJ', 'AUX', 'v\\n'], ['verbe ÊTRE conjugué', 'VER', 'Vuc', 'EJ', 'VERB', 'v\\n']], 'Cc': [['conjonction de coordination', 'CON', 'Cc', 'CONJO', 'CCONJ', 'conj\\n']], 'Cs': [['conjonction de subordination', 'CON', 'Cs', 'CONJS', 'SCONJ', 'conj\\n'], ['conjonction de subordination', 'CON', 'Cs', 'WH', 'SCONJ', 'conj\\n']], 'Da': [['déterminant défini (article défini)', 'DET', 'Da', 'D', 'DET', 'art\\n']], 'Dn': [['déterminant indéfini (article indéfini)', 'DET', 'Dn', 'D', 'DET', 'art\\n'], ['déterminant indéfini (article indéfini)', 'DET', 'Dn', 'Q', 'DET', 'art\\n']], 'Di': [['déterminant indéfini (autre)', 'DET', 'Di', 'D', 'DET', 'art\\n'], ['déterminant indéfini (autre)', 'DET', 'Di', 'Q', 'DET', 'art\\n']], 'Dd': [['déterminant démonstratif', 'DET', 'Dd', 'D', 'DET', 'art\\n']], 'Dp': [['déterminant partitif', 'DET', 'Dp', 'D', 'DET', 'art\\n']], 'Dt': [['déterminant interrogatif/exclamatif', 'DET', 'Dt', 'WD', 'DET', 'art\\n']], 'Dr': [['déterminant relatif', 'DET', 'Dr', 'WD', 'DET', 'art\\n']], 'Ds': [['déterminant possessif', 'DET', 'Ds', 'DZ', 'DET', 'art\\n']], 'Nc': [['nom commun au pluriel', 'NOM', 'Nc', 'NCPL', 'NOUN', 's\\n'], ['nom commun au singulier', 'NOM', 'Nc', 'NCS', 'NOUN', 's\\n']], 'Np': [['nom propre au pluriel', 'NOMP', 'Np', 'NPRPL', 'PROPN', 's\\n'], ['nom propre au singulier', 'NOMP', 'Np', 'NPRS', 'PROPN', 's\\n']], 'Mc': [['Numéral', 'NUM', 'Mc', 'NUM', 'NUM', 'num\\n']], 'Mo': [['Numéral', 'NUM', 'Mo', 'NUM', 'NUM', 'num\\n']], 'S+Da': [['préposition et déterminant défini contractés', 'PREP+DET', 'S+Da', 'P', 'ADP', 'prep\\n']], 'S+Dr': [['préposition et déterminant relatif contractés', 'PREP+DET', 'S+Dr', 'P', 'ADP', 'prep\\n']], 'S+Pr': [['préposition et pronom relatif contractés', 'PREP+PRO', 'S+Pr', 'P', 'ADP', 'prep\\n']], 'S': [['préposition', 'PREP', 'S', 'P', 'ADP', 'prep\\n']], 'Pt': [['pronom interrogatif/exclamatif', 'PRO', 'Pt', 'WPRO', 'PRON', 'pron\\n']], 'Pr': [['pronom relatif ', 'PRO', 'Pr', 'WPRO', 'PRON', 'pron\\n']], 'Pp': [['pronom personnel', 'PRO', 'Pp', 'PRO', 'PRON', 'pron\\n']], 'Pd': [['pronom démonstratif', 'PRO', 'Pd', 'PRO', 'PRON', 'pron\\n']], 'Pi': [['pronom indéfini (autre)', 'PRO', 'Pi', 'PRO', 'PRON', 'pron\\n'], ['pronom indéfini (autre)', 'PRO', 'Pi', 'Q', 'PRON', 'pron\\n']], 'Ps': [['pronom possessif', 'PRO', 'Ps', 'PRO', 'PRON', 'pron\\n']], 'Vvn': [[\"verbe semi-auxiliaire* à l'infinitif (emploi non-modal**)\", 'VER', 'Vvn', 'MDX', 'VERB', 'v\\n'], [\"verbe semi-auxiliaire* à l'infinitif (emploi modal***)\", 'VER', 'Vvn', 'MDX', 'AUX', 'v\\n'], [\"verbe principal à l'infinitif\", 'VER', 'Vvn', 'VX', 'VERB', 'v\\n']], 'Vvc': [['verbe semi-auxiliaire* conjugué (emploi non-modal**)', 'VER', 'Vvc', 'MDJ', 'VERB', 'v\\n'], ['verbe semi-auxiliaire* conjugué (emploi modal***)', 'VER', 'Vvc', 'MDJ', 'AUX', 'v\\n'], ['verbe principal conjugué', 'VER', 'Vvc', 'VJ', 'VERB', 'v\\n']], 'Xe': [['Foreign word', '_', 'Xe', 'FW', 'X', '_\\n']], 'INT': [['Interjection', 'INT', 'INT', 'ITJ', 'INTJ', 'interj\\n']], 'Fs': [['ponctuation à la fin de la proposition', 'PUNC', 'Fs', 'PONFP', 'PUNCT', '_\\n']], 'Fw': [['ponctuation au milieu de la proposition', 'PUNC', 'Fw', 'PON', 'PUNCT', '_\\n']], 'Xa': [['parties du discours difficiles à interpréter', 'RES', 'Xa', 'X', 'X', '_']]}\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree as ET\n",
    "from utils import make_d_CorrTable\n",
    "\n",
    "path_CorrTable = '/home/ziane212/projects/HT_CRISCO-main/workflow_HT/ressources/MICLE_CorrTable_coherence_26.10.23.csv'\n",
    "def make_d_CorrTable(path_CorrTable):\n",
    "    '''\n",
    "    url = \"https://unicloud.unicaen.fr/index.php/s/An5wqjdLHiPFwKt/download/dico_PRESTO_SIMPLE_10.01.23.dff\"\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    path_CorrTable = '/home/ziane212/crisco_work_ressources/test/corrTable.csv'\n",
    "    open(path_CorrTable, 'wb').write(r.content)\n",
    "    '''\n",
    "    #création du dictionnaire python à partir de la table de conversion\n",
    "    CorrTable = open(path_CorrTable, encoding='utf-8')\n",
    "    d_CorrTable = {}\n",
    "    for i in CorrTable:\n",
    "        i = i.split(\",\")\n",
    "        if i[2] in d_CorrTable:\n",
    "            d_CorrTable[i[2]].append(i)\n",
    "        else:\n",
    "            d_CorrTable[i[2]]=[i]\n",
    "            \n",
    "    CorrTable.close()\n",
    "\n",
    "    return d_CorrTable\n",
    "\n",
    "def make_d_CorrTable_UP(path_CorrTable):\n",
    "    '''\n",
    "    url = \"https://unicloud.unicaen.fr/index.php/s/An5wqjdLHiPFwKt/download/dico_PRESTO_SIMPLE_10.01.23.dff\"\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    path_CorrTable = '/home/ziane212/crisco_work_ressources/test/corrTable.csv'\n",
    "    open(path_CorrTable, 'wb').write(r.content)\n",
    "    '''\n",
    "    #création du dictionnaire python à partir de la table de conversion\n",
    "    CorrTable = open(path_CorrTable, encoding='utf-8')\n",
    "    d_CorrTable = {}\n",
    "    for i in CorrTable:\n",
    "        i = i.split(\",\")\n",
    "        if i[3] in d_CorrTable:\n",
    "            d_CorrTable[i[3]].append(i)\n",
    "        else:\n",
    "            d_CorrTable[i[3]]=[i]\n",
    "            \n",
    "    CorrTable.close()\n",
    "\n",
    "    return d_CorrTable\n",
    "\n",
    "d_CorrTable = make_d_CorrTable(path_CorrTable)\n",
    "d_CorrTable_UP = make_d_CorrTable_UP(path_CorrTable)\n",
    "\n",
    "inputfile = '/home/ziane212/Téléchargements/13e_Histoire_ducs_convTags_RevNR-final.xml'\n",
    "outputfile = '/home/ziane212/Téléchargements/13e_Histoire_ducs_convTags_test.xml'\n",
    "\n",
    "# Charger le fichier XML\n",
    "tree = ET.parse(open(inputfile, encoding='utf-8'))\n",
    "root = tree.getroot()\n",
    "\n",
    "VERB_list = ['Ga', \n",
    "             'Vuc',\n",
    "             'Ge',\n",
    "             'Vun',\n",
    "             'Vvc',\n",
    "             'Vvn'\n",
    "             ]\n",
    "\n",
    "# Parcourir tous les éléments avec l'attribut \"prpos\"\n",
    "for w in root.findall('.//w'):\n",
    "    prpos = w.get('prpos')\n",
    "    if prpos in VERB_list:\n",
    "        uppos = w.get('uppos')\n",
    "        if uppos in d_CorrTable_UP:\n",
    "            upos = d_CorrTable_UP[uppos][0][4]\n",
    "    else:\n",
    "        if prpos in d_CorrTable:\n",
    "            upos = d_CorrTable[prpos][0][4]\n",
    "    \n",
    "    w.set('udpos', upos)\n",
    "\n",
    "ET.ElementTree(root).write(outputfile, encoding=\"utf-8\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_div, indent_xml\n",
    "from lxml import etree as ET\n",
    "\n",
    "inputfile = \"/home/ziane212/projects/Gascon/1564_Stil_de_la_justicy/1564_Stil_de_la_justicy_Paginated_segTok_renum.xml\"\n",
    "cible = \"/home/ziane212/projects/Gascon/1564_Stil_de_la_justicy/1564_Stil_de_la_justicy_Paginated_segTok.xml\"\n",
    "tree = ET.parse(open(inputfile, encoding='utf-8'))\n",
    "root = tree.getroot()\n",
    "\n",
    "root = build_div(root, 'section')\n",
    "root = build_div(root, 'chapter')\n",
    "root = build_div(root, 'book')\n",
    "indent_xml(root)\n",
    "\n",
    "ET.ElementTree(root).write(cible, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "def move_hyphen_words_to_note(xml_tree):\n",
    "    for paragraph in xml_tree.xpath('.//p'):\n",
    "        for sentence in paragraph.xpath('.//s'):\n",
    "            note = etree.Element('note')\n",
    "            for word in sentence.xpath('.//w'):\n",
    "                if word.text == '—':\n",
    "                    note.append(word)\n",
    "\n",
    "            # Insérer la balise <note> avant la balise <s>\n",
    "            if len(note) != 0:\n",
    "                paragraph.insert(paragraph.index(sentence), note)\n",
    "\n",
    "def process_xml(input_file, output_file):\n",
    "    tree = etree.parse(input_file)\n",
    "\n",
    "    for paragraph in tree.xpath('.//p'):\n",
    "        for sentence in paragraph.xpath('.//s'):\n",
    "            len_sent = sum(1 for _ in sentence.xpath('.//w'))\n",
    "\n",
    "    move_hyphen_words_to_note(tree)\n",
    "\n",
    "    tree.write(output_file, pretty_print=True, encoding='utf-8')\n",
    "\n",
    "\n",
    "process_xml('/home/ziane212/projects/Gascon/1468_Livre_noir_de_Dax/1468_Livre_noir_de_Dax_pp.31-177_segTok.22.11.23.xml',\n",
    "            '/home/ziane212/projects/Gascon/1468_Livre_noir_de_Dax/1468_Livre_noir_de_Dax_pp.31-177_segTok.22.11.23_test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
